<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>語音聊天助理</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            width: 100%;
            max-width: 600px;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
        }

        h1 {
            color: #fff;
            text-align: center;
            margin-bottom: 30px;
            font-size: 1.8rem;
        }

        .chat-container {
            height: 400px;
            overflow-y: auto;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 15px;
            padding: 20px;
            margin-bottom: 20px;
        }

        .message {
            margin-bottom: 15px;
            padding: 12px 16px;
            border-radius: 12px;
            max-width: 85%;
            animation: fadeIn 0.3s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .user-message {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            margin-left: auto;
            text-align: right;
        }

        .assistant-message {
            background: rgba(255, 255, 255, 0.15);
            color: #e0e0e0;
        }

        .controls {
            display: flex;
            gap: 15px;
            justify-content: center;
            flex-wrap: wrap;
        }

        .btn {
            padding: 15px 30px;
            border: none;
            border-radius: 50px;
            font-size: 1rem;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .btn-talk {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            min-width: 200px;
            justify-content: center;
        }

        .btn-talk:hover {
            transform: scale(1.05);
            box-shadow: 0 5px 20px rgba(102, 126, 234, 0.4);
        }

        .btn-talk.connected {
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
        }

        .btn-talk.talking {
            background: linear-gradient(135deg, #ff416c 0%, #ff4b2b 100%);
            animation: pulse 0.5s infinite;
        }

        .btn-talk.ai-speaking {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            animation: glow 1s infinite;
        }

        @keyframes pulse {
            0%, 100% { box-shadow: 0 0 0 0 rgba(255, 65, 108, 0.7); }
            50% { box-shadow: 0 0 0 15px rgba(255, 65, 108, 0); }
        }

        @keyframes glow {
            0%, 100% { box-shadow: 0 0 10px rgba(245, 87, 108, 0.5); }
            50% { box-shadow: 0 0 25px rgba(245, 87, 108, 0.8); }
        }

        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .status {
            text-align: center;
            color: #aaa;
            margin-top: 15px;
            font-size: 0.9rem;
            min-height: 24px;
        }

        .status.error {
            color: #ff6b6b;
        }

        .status.connected {
            color: #38ef7d;
        }

        .settings {
            margin-bottom: 20px;
            padding: 15px;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 10px;
        }

        .settings label {
            color: #ccc;
            font-size: 0.9rem;
        }

        .settings select, .settings input {
            width: 100%;
            padding: 10px;
            margin-top: 5px;
            border: none;
            border-radius: 8px;
            background: rgba(255, 255, 255, 0.1);
            color: white;
            font-size: 0.9rem;
        }

        /* Login styles */
        .login-container {
            display: flex;
            flex-direction: column;
            gap: 15px;
        }

        .login-container input {
            width: 100%;
            padding: 12px 16px;
            border: none;
            border-radius: 10px;
            background: rgba(255, 255, 255, 0.1);
            color: white;
            font-size: 1rem;
        }

        .login-container input::placeholder {
            color: rgba(255, 255, 255, 0.5);
        }

        .btn-login {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            width: 100%;
            justify-content: center;
        }

        .btn-login:hover {
            transform: scale(1.02);
            box-shadow: 0 5px 20px rgba(102, 126, 234, 0.4);
        }

        .btn-login:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }

        .login-error {
            color: #ff6b6b;
            text-align: center;
            font-size: 0.9rem;
            min-height: 20px;
        }

        .main-content {
            display: none;
        }

        .main-content.visible {
            display: block;
        }

        .login-section {
            display: block;
        }

        .login-section.hidden {
            display: none;
        }

        .settings select option {
            background: #1a1a2e;
        }

        .voice-select {
            margin-bottom: 10px;
        }

        .chat-container::-webkit-scrollbar {
            width: 8px;
        }

        .chat-container::-webkit-scrollbar-track {
            background: rgba(0, 0, 0, 0.2);
            border-radius: 4px;
        }

        .chat-container::-webkit-scrollbar-thumb {
            background: rgba(255, 255, 255, 0.2);
            border-radius: 4px;
        }

        .text-input-container {
            display: flex;
            gap: 10px;
            margin-top: 15px;
        }

        .text-input {
            flex: 1;
            padding: 12px 16px;
            border: none;
            border-radius: 25px;
            background: rgba(255, 255, 255, 0.1);
            color: white;
            font-size: 1rem;
        }

        .text-input::placeholder {
            color: rgba(255, 255, 255, 0.5);
        }

        .btn-send {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 12px 25px;
        }

        .btn-send:hover {
            transform: scale(1.05);
        }

        .transcript {
            font-size: 0.85rem;
            color: #888;
            font-style: italic;
            margin-top: 5px;
        }

        .connection-indicator {
            display: inline-block;
            width: 10px;
            height: 10px;
            border-radius: 50%;
            margin-right: 8px;
            background: #ff4444;
        }

        .connection-indicator.connected {
            background: #44ff44;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>語音聊天助理</h1>

        <!-- Login Section -->
        <div class="login-section" id="loginSection">
            <div class="login-container">
                <input type="text" id="userIdInput" placeholder="使用者帳號">
                <input type="password" id="passwordInput" placeholder="密碼">
                <button class="btn btn-login" id="loginBtn">登入</button>
                <div class="login-error" id="loginError"></div>
            </div>
        </div>

        <!-- Main Content (hidden until login) -->
        <div class="main-content" id="mainContent">
            <div class="settings">
                <div class="voice-select">
                    <label>AI 語音選擇：</label>
                    <select id="voiceSelect">
                        <option value="alloy">Alloy</option>
                        <option value="ash">Ash</option>
                        <option value="coral" selected>Coral</option>
                        <option value="echo">Echo</option>
                        <option value="sage">Sage</option>
                        <option value="shimmer">Shimmer</option>
                    </select>
                </div>
            </div>

            <div class="chat-container" id="chatContainer">
                <div class="message assistant-message">
                    你好！我是你的即時語音助理。點擊下方按鈕開始對話，鬆開結束說話。
                </div>
            </div>

            <div class="controls">
                <button class="btn btn-talk" id="talkBtn" disabled>
                    <span class="connection-indicator" id="connectionIndicator"></span>
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor">
                        <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"/>
                        <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
                    </svg>
                    <span id="talkBtnText">連線中...</span>
                </button>
            </div>

            <div class="text-input-container">
                <input type="text" class="text-input" id="textInput" placeholder="或輸入文字訊息...">
                <button class="btn btn-send" id="sendBtn">發送</button>
            </div>

            <div class="status" id="status"></div>
        </div>
    </div>

    <script>
        // OpenAI API Key (will be fetched from server)
        let API_KEY = '';

        // API Key endpoint
        const API_KEY_ENDPOINT = 'https://script.google.com/macros/s/AKfycbwzY0bAkixaexeIMNpxlPi_9LZC2vtgI78Uh3llpBtglQeSdiCLn3wedAL-f1GCcGF-Wg/exec';

        // Realtime API WebSocket
        const REALTIME_API_URL = 'wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17';

        // Login DOM Elements
        const loginSection = document.getElementById('loginSection');
        const mainContent = document.getElementById('mainContent');
        const userIdInput = document.getElementById('userIdInput');
        const passwordInput = document.getElementById('passwordInput');
        const loginBtn = document.getElementById('loginBtn');
        const loginError = document.getElementById('loginError');

        // DOM Elements
        const talkBtn = document.getElementById('talkBtn');
        const talkBtnText = document.getElementById('talkBtnText');
        const connectionIndicator = document.getElementById('connectionIndicator');
        const sendBtn = document.getElementById('sendBtn');
        const textInput = document.getElementById('textInput');
        const chatContainer = document.getElementById('chatContainer');
        const status = document.getElementById('status');
        const voiceSelect = document.getElementById('voiceSelect');

        // State
        let ws = null;
        let audioContext = null;
        let mediaStream = null;
        let audioWorkletNode = null;
        let isConnected = false;
        let isTalking = false;
        let isAISpeaking = false;
        let currentUserTranscript = '';
        let currentAssistantTranscript = '';
        let currentUserMessageEl = null;
        let currentAssistantMessageEl = null;

        // Audio playback
        let audioQueue = [];
        let isPlaying = false;
        let nextPlayTime = 0;

        // Login function
        async function login(userId, password) {
            loginBtn.disabled = true;
            loginBtn.textContent = '登入中...';
            loginError.textContent = '';

            try {
                const response = await fetch(API_KEY_ENDPOINT, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'text/plain',
                    },
                    body: JSON.stringify({
                        userid: userId,
                        pwd: password
                    }),
                    redirect: 'follow'
                });

                const data = await response.json();

                if (data.status === "success" && data.apiKey) {
                    API_KEY = data.apiKey;
                    loginSection.classList.add('hidden');
                    mainContent.classList.add('visible');
                    await init();
                    return true;
                } else {
                    loginError.textContent = data.message || '登入失敗，請檢查帳號密碼';
                    return false;
                }
            } catch (error) {
                console.error('登入錯誤:', error);
                loginError.textContent = '連線錯誤，請稍後再試';
                return false;
            } finally {
                loginBtn.disabled = false;
                loginBtn.textContent = '登入';
            }
        }

        // Initialize
        async function init() {
            updateStatus('正在初始化...');

            try {
                // Request microphone access
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: 24000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });

                // Initialize audio context
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });

                // Connect to Realtime API
                await connectWebSocket();

            } catch (error) {
                console.error('初始化錯誤:', error);
                updateStatus('初始化失敗: ' + error.message, true);
            }
        }

        // Connect to OpenAI Realtime API
        async function connectWebSocket() {
            updateStatus('正在連線到 OpenAI...');

            ws = new WebSocket(REALTIME_API_URL, [
                'realtime',
                `openai-insecure-api-key.${API_KEY}`,
                'openai-beta.realtime-v1'
            ]);

            ws.onopen = () => {
                console.log('WebSocket 已連線');
                isConnected = true;
                updateConnectionState();

                // Configure session
                const voice = voiceSelect.value;
                ws.send(JSON.stringify({
                    type: 'session.update',
                    session: {
                        modalities: ['text', 'audio'],
                        instructions: '你是一個友善且有幫助的AI助理。請用繁體中文回答問題，回答要簡潔明瞭、自然流暢。',
                        voice: voice,
                        input_audio_format: 'pcm16',
                        output_audio_format: 'pcm16',
                        input_audio_transcription: {
                            model: 'whisper-1'
                        },
                        turn_detection: {
                            type: 'server_vad',
                            threshold: 0.5,
                            prefix_padding_ms: 300,
                            silence_duration_ms: 500
                        }
                    }
                }));

                updateStatus('已連線 - 按住按鈕開始說話');
            };

            ws.onmessage = (event) => {
                const data = JSON.parse(event.data);
                handleRealtimeEvent(data);
            };

            ws.onerror = (error) => {
                console.error('WebSocket 錯誤:', error);
                updateStatus('連線錯誤', true);
            };

            ws.onclose = (event) => {
                console.log('WebSocket 已關閉:', event.code, event.reason);
                isConnected = false;
                updateConnectionState();

                // Attempt to reconnect after 3 seconds
                if (API_KEY) {
                    setTimeout(() => {
                        updateStatus('正在重新連線...');
                        connectWebSocket();
                    }, 3000);
                }
            };
        }

        // Handle Realtime API events
        function handleRealtimeEvent(event) {
            console.log('收到事件:', event.type);

            switch (event.type) {
                case 'session.created':
                case 'session.updated':
                    console.log('Session 已更新');
                    break;

                case 'input_audio_buffer.speech_started':
                    // User started speaking
                    if (!currentUserMessageEl) {
                        currentUserTranscript = '';
                        currentUserMessageEl = addMessage('', true);
                    }
                    updateStatus('正在聆聽...');
                    break;

                case 'input_audio_buffer.speech_stopped':
                    // User stopped speaking
                    updateStatus('處理中...');
                    break;

                case 'conversation.item.input_audio_transcription.completed':
                    // User speech transcription
                    if (event.transcript) {
                        currentUserTranscript = event.transcript;
                        if (currentUserMessageEl) {
                            currentUserMessageEl.textContent = currentUserTranscript;
                        }
                    }
                    break;

                case 'response.created':
                    // AI response started
                    currentAssistantTranscript = '';
                    currentAssistantMessageEl = addMessage('', false);
                    break;

                case 'response.audio_transcript.delta':
                    // AI text transcript delta
                    if (event.delta) {
                        currentAssistantTranscript += event.delta;
                        if (currentAssistantMessageEl) {
                            currentAssistantMessageEl.textContent = currentAssistantTranscript;
                        }
                    }
                    break;

                case 'response.audio.delta':
                    // AI audio delta
                    if (event.delta) {
                        const audioData = base64ToArrayBuffer(event.delta);
                        playAudioChunk(audioData);
                    }
                    if (!isAISpeaking) {
                        isAISpeaking = true;
                        updateButtonState();
                        updateStatus('AI 正在回應...');
                    }
                    break;

                case 'response.audio.done':
                    // AI audio complete
                    break;

                case 'response.done':
                    // AI response complete
                    isAISpeaking = false;
                    currentUserMessageEl = null;
                    currentAssistantMessageEl = null;
                    updateButtonState();
                    updateStatus('已連線 - 按住按鈕開始說話');
                    break;

                case 'error':
                    console.error('Realtime API 錯誤:', event.error);
                    updateStatus('錯誤: ' + (event.error?.message || '未知錯誤'), true);
                    break;
            }
        }

        // Base64 to ArrayBuffer
        function base64ToArrayBuffer(base64) {
            const binaryString = atob(base64);
            const bytes = new Uint8Array(binaryString.length);
            for (let i = 0; i < binaryString.length; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        // ArrayBuffer to Base64
        function arrayBufferToBase64(buffer) {
            const bytes = new Uint8Array(buffer);
            let binary = '';
            for (let i = 0; i < bytes.byteLength; i++) {
                binary += String.fromCharCode(bytes[i]);
            }
            return btoa(binary);
        }

        // Play audio chunk
        function playAudioChunk(arrayBuffer) {
            if (!audioContext) return;

            // Convert PCM16 to Float32
            const int16Array = new Int16Array(arrayBuffer);
            const float32Array = new Float32Array(int16Array.length);
            for (let i = 0; i < int16Array.length; i++) {
                float32Array[i] = int16Array[i] / 32768.0;
            }

            // Create audio buffer
            const audioBuffer = audioContext.createBuffer(1, float32Array.length, 24000);
            audioBuffer.getChannelData(0).set(float32Array);

            // Play
            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);

            const currentTime = audioContext.currentTime;
            if (nextPlayTime < currentTime) {
                nextPlayTime = currentTime;
            }
            source.start(nextPlayTime);
            nextPlayTime += audioBuffer.duration;
        }

        // Start recording and streaming audio
        async function startTalking() {
            if (!isConnected || !mediaStream || isTalking) return;

            isTalking = true;
            updateButtonState();

            // Resume audio context if suspended
            if (audioContext.state === 'suspended') {
                await audioContext.resume();
            }

            // Create audio processing
            const source = audioContext.createMediaStreamSource(mediaStream);

            // Use ScriptProcessorNode for audio capture (simpler than AudioWorklet)
            const bufferSize = 4096;
            const scriptProcessor = audioContext.createScriptProcessor(bufferSize, 1, 1);

            scriptProcessor.onaudioprocess = (event) => {
                if (!isTalking || !isConnected) return;

                const inputData = event.inputBuffer.getChannelData(0);

                // Convert Float32 to PCM16
                const pcm16 = new Int16Array(inputData.length);
                for (let i = 0; i < inputData.length; i++) {
                    const s = Math.max(-1, Math.min(1, inputData[i]));
                    pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                }

                // Send to WebSocket
                const base64Audio = arrayBufferToBase64(pcm16.buffer);
                ws.send(JSON.stringify({
                    type: 'input_audio_buffer.append',
                    audio: base64Audio
                }));
            };

            source.connect(scriptProcessor);
            scriptProcessor.connect(audioContext.destination);

            // Store for cleanup
            audioWorkletNode = { source, scriptProcessor };

            updateStatus('正在錄音...');
        }

        // Stop recording
        function stopTalking() {
            if (!isTalking) return;

            isTalking = false;

            // Cleanup audio nodes
            if (audioWorkletNode) {
                audioWorkletNode.source.disconnect();
                audioWorkletNode.scriptProcessor.disconnect();
                audioWorkletNode = null;
            }

            // Commit the audio buffer
            if (isConnected && ws) {
                ws.send(JSON.stringify({
                    type: 'input_audio_buffer.commit'
                }));
            }

            updateButtonState();
            updateStatus('處理中...');
        }

        // Send text message
        function sendTextMessage(text) {
            if (!text.trim() || !isConnected) return;

            textInput.value = '';

            // Add user message to chat
            addMessage(text, true);

            // Send to API
            ws.send(JSON.stringify({
                type: 'conversation.item.create',
                item: {
                    type: 'message',
                    role: 'user',
                    content: [{
                        type: 'input_text',
                        text: text
                    }]
                }
            }));

            // Request response
            ws.send(JSON.stringify({
                type: 'response.create'
            }));
        }

        // Update connection state UI
        function updateConnectionState() {
            if (isConnected) {
                connectionIndicator.classList.add('connected');
                talkBtn.disabled = false;
                talkBtnText.textContent = '按住說話';
            } else {
                connectionIndicator.classList.remove('connected');
                talkBtn.disabled = true;
                talkBtnText.textContent = '連線中...';
            }
        }

        // Update button state
        function updateButtonState() {
            talkBtn.classList.remove('connected', 'talking', 'ai-speaking');

            if (isAISpeaking) {
                talkBtn.classList.add('ai-speaking');
                talkBtnText.textContent = 'AI 回應中...';
            } else if (isTalking) {
                talkBtn.classList.add('talking');
                talkBtnText.textContent = '正在錄音...';
            } else if (isConnected) {
                talkBtn.classList.add('connected');
                talkBtnText.textContent = '按住說話';
            }
        }

        // Update status
        function updateStatus(message, isError = false) {
            status.textContent = message;
            status.className = 'status';
            if (isError) {
                status.classList.add('error');
            } else if (isConnected) {
                status.classList.add('connected');
            }
        }

        // Add message to chat
        function addMessage(text, isUser = false) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${isUser ? 'user-message' : 'assistant-message'}`;
            messageDiv.textContent = text || '...';
            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
            return messageDiv;
        }

        // Voice selection change handler
        voiceSelect.addEventListener('change', () => {
            if (isConnected && ws) {
                ws.send(JSON.stringify({
                    type: 'session.update',
                    session: {
                        voice: voiceSelect.value
                    }
                }));
            }
        });

        // Talk button events (press and hold)
        talkBtn.addEventListener('mousedown', (e) => {
            e.preventDefault();
            startTalking();
        });

        talkBtn.addEventListener('mouseup', (e) => {
            e.preventDefault();
            stopTalking();
        });

        talkBtn.addEventListener('mouseleave', (e) => {
            if (isTalking) {
                stopTalking();
            }
        });

        // Touch events for mobile
        talkBtn.addEventListener('touchstart', (e) => {
            e.preventDefault();
            startTalking();
        });

        talkBtn.addEventListener('touchend', (e) => {
            e.preventDefault();
            stopTalking();
        });

        // Text input events
        sendBtn.addEventListener('click', () => {
            sendTextMessage(textInput.value);
        });

        textInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                sendTextMessage(textInput.value);
            }
        });

        // Login event listeners
        loginBtn.addEventListener('click', () => {
            const userId = userIdInput.value.trim();
            const password = passwordInput.value;
            if (userId && password) {
                login(userId, password);
            } else {
                loginError.textContent = '請輸入帳號和密碼';
            }
        });

        passwordInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                loginBtn.click();
            }
        });

        userIdInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                passwordInput.focus();
            }
        });

        // Cleanup on page unload
        window.addEventListener('beforeunload', () => {
            if (ws) {
                ws.close();
            }
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
            }
        });
    </script>
</body>
</html>
